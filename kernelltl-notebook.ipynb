{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c331304d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-13T14:27:20.859046Z",
     "iopub.status.busy": "2025-10-13T14:27:20.858830Z",
     "iopub.status.idle": "2025-10-13T14:27:22.184782Z",
     "shell.execute_reply": "2025-10-13T14:27:22.184056Z"
    },
    "papermill": {
     "duration": 1.330258,
     "end_time": "2025-10-13T14:27:22.186004",
     "exception": false,
     "start_time": "2025-10-13T14:27:20.855746",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'KernelLTL'...\r\n",
      "remote: Enumerating objects: 248, done.\u001b[K\r\n",
      "remote: Counting objects: 100% (23/23), done.\u001b[K\r\n",
      "remote: Compressing objects: 100% (15/15), done.\u001b[K\r\n",
      "remote: Total 248 (delta 7), reused 18 (delta 6), pack-reused 225 (from 1)\u001b[K\r\n",
      "Receiving objects: 100% (248/248), 99.18 KiB | 923.00 KiB/s, done.\r\n",
      "Resolving deltas: 100% (136/136), done.\r\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/MeesLursen/KernelLTL.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bdd0c091",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-13T14:27:22.191964Z",
     "iopub.status.busy": "2025-10-13T14:27:22.191732Z",
     "iopub.status.idle": "2025-10-13T14:27:22.918907Z",
     "shell.execute_reply": "2025-10-13T14:27:22.917964Z"
    },
    "papermill": {
     "duration": 0.731648,
     "end_time": "2025-10-13T14:27:22.920395",
     "exception": false,
     "start_time": "2025-10-13T14:27:22.188747",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already up to date.\r\n"
     ]
    }
   ],
   "source": [
    "!cd /kaggle/working/KernelLTL && git pull && cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b73d7e13",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-13T14:27:22.926043Z",
     "iopub.status.busy": "2025-10-13T14:27:22.925801Z",
     "iopub.status.idle": "2025-10-13T14:27:22.929667Z",
     "shell.execute_reply": "2025-10-13T14:27:22.929025Z"
    },
    "papermill": {
     "duration": 0.007996,
     "end_time": "2025-10-13T14:27:22.930791",
     "exception": false,
     "start_time": "2025-10-13T14:27:22.922795",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"/kaggle/working/KernelLTL\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d021c30c",
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2025-10-13T14:27:22.936175Z",
     "iopub.status.busy": "2025-10-13T14:27:22.935622Z",
     "iopub.status.idle": "2025-10-13T14:30:35.613020Z",
     "shell.execute_reply": "2025-10-13T14:30:35.612157Z"
    },
    "papermill": {
     "duration": 192.681565,
     "end_time": "2025-10-13T14:30:35.614521",
     "exception": false,
     "start_time": "2025-10-13T14:27:22.932956",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bin/micromamba\r\n",
      "\u001b[?25l\u001b[2K\u001b[0G\u001b[?25h\u001b[?25l\u001b[2K\u001b[0G[+] 0.0s\r\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 0.1s\r\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 0.2s\r\n",
      "conda-forge/linux-64 \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m 804.3kB /  47.8MB @   4.6MB/s  0.1s\r\n",
      "conda-forge/noarch   ━╸\u001b[90m━━━━━━━━━━━━━━━━━━━━━\u001b[0m   2.8MB /  22.8MB @  16.0MB/s  0.1s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 0.3s\r\n",
      "conda-forge/linux-64 ━╸\u001b[90m━━━━━━━━━━━━━━━━━━━━━\u001b[0m   5.6MB /  47.8MB @  19.9MB/s  0.2s\r\n",
      "conda-forge/noarch   ━━━━━━━╸\u001b[90m━━━━━━━━━━━━━━━\u001b[0m   8.3MB /  22.8MB @  29.5MB/s  0.2s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 0.4s\r\n",
      "conda-forge/linux-64 ━━╸\u001b[90m━━━━━━━━━━━━━━━━━━━━\u001b[0m   8.1MB /  47.8MB @  21.2MB/s  0.3s\r\n",
      "conda-forge/noarch   ━━━━━━━━━━━╸\u001b[90m━━━━━━━━━━━\u001b[0m  12.5MB /  22.8MB @  32.7MB/s  0.3s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 0.5s\r\n",
      "conda-forge/linux-64 ━━━━╸\u001b[90m━━━━━━━━━━━━━━━━━━\u001b[0m  12.5MB /  47.8MB @  25.7MB/s  0.4s\r\n",
      "conda-forge/noarch   ━━━━━━━━━━━━━━━━╸\u001b[90m━━━━━━\u001b[0m  17.6MB /  22.8MB @  35.9MB/s  0.4s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 0.6s\r\n",
      "conda-forge/linux-64 ━━━━━━━╸\u001b[90m━━━━━━━━━━━━━━━\u001b[0m  17.7MB /  47.8MB @  29.9MB/s  0.5s\r\n",
      "conda-forge/noarch   ━━━━━━━━━━━━━━━━━━━━━╸\u001b[90m━\u001b[0m  22.6MB /  22.8MB @  38.2MB/s  0.5s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Gconda-forge/noarch                                  22.8MB @  38.2MB/s  0.6s\r\n",
      "[+] 0.7s\r\n",
      "conda-forge/linux-64 ━━━━━━━╸\u001b[90m━━━━━━━━━━━━━━━\u001b[0m  18.0MB /  47.8MB @  25.9MB/s  0.6s\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 0.8s\r\n",
      "conda-forge/linux-64 ━━━━━━━━━━━━╸\u001b[90m━━━━━━━━━━\u001b[0m  27.7MB /  47.8MB @  34.8MB/s  0.7s\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 0.9s\r\n",
      "conda-forge/linux-64 ━━━━━━━━━━━━━━╸\u001b[90m━━━━━━━━\u001b[0m  32.4MB /  47.8MB @  38.2MB/s  0.8s\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 1.0s\r\n",
      "conda-forge/linux-64 ━━━━━━━━━━━━━━━━━╸\u001b[90m━━━━━\u001b[0m  38.6MB /  47.8MB @  40.0MB/s  0.9s\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 1.1s\r\n",
      "conda-forge/linux-64 ━━━━━━━━━━━━━━━━━━━╸\u001b[90m━━━\u001b[0m  43.9MB /  47.8MB @  40.6MB/s  1.0s\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 1.2s\r\n",
      "conda-forge/linux-64 ━━━━━━━━━━━━━━━━━━━━╸\u001b[90m━━\u001b[0m  45.9MB /  47.8MB @  40.5MB/s  1.1s\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 1.3s\r\n",
      "conda-forge/linux-64 ━━━━━━━━━━━━━━━━━━━━╸\u001b[90m━━\u001b[0m  45.9MB /  47.8MB @  40.5MB/s  1.2s\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 1.4s\r\n",
      "conda-forge/linux-64 ━━━━━━━━━━━━━━━━━━━━╸\u001b[90m━━\u001b[0m  45.9MB /  47.8MB @  40.5MB/s  1.3s\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 1.5s\r\n",
      "conda-forge/linux-64 ━━━━━━━━━━━━━━━━━━━━╸\u001b[90m━━\u001b[0m  45.9MB /  47.8MB @  40.5MB/s  1.4s\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 1.6s\r\n",
      "conda-forge/linux-64 ━━━━━━━━━━━━━━━━━━━━╸\u001b[90m━━\u001b[0m  45.9MB /  47.8MB @  40.5MB/s  1.5s\u001b[2K\u001b[1A\u001b[2K\u001b[0Gconda-forge/linux-64                                47.8MB @  40.5MB/s  1.5s\r\n",
      "\u001b[?25h\r\n",
      "\r\n",
      "Transaction\r\n",
      "\r\n",
      "  Prefix: /root/.local/share/mamba/envs/kernelltl\r\n",
      "\r\n",
      "  Updating specs:\r\n",
      "\r\n",
      "   - python=3.13.7\r\n",
      "   - pip\r\n",
      "\r\n",
      "\r\n",
      "  Package               Version  Build               Channel          Size\r\n",
      "────────────────────────────────────────────────────────────────────────────\r\n",
      "  Install:\r\n",
      "────────────────────────────────────────────────────────────────────────────\r\n",
      "\r\n",
      "  \u001b[32m+ _libgcc_mutex   \u001b[0m        0.1  conda_forge         conda-forge       3kB\r\n",
      "  \u001b[32m+ _openmp_mutex   \u001b[0m        4.5  2_gnu               conda-forge      24kB\r\n",
      "  \u001b[32m+ bzip2           \u001b[0m      1.0.8  hda65f42_8          conda-forge     260kB\r\n",
      "  \u001b[32m+ ca-certificates \u001b[0m  2025.10.5  hbd8a1cb_0          conda-forge     156kB\r\n",
      "  \u001b[32m+ ld_impl_linux-64\u001b[0m       2.44  ha97dd6f_2          conda-forge     747kB\r\n",
      "  \u001b[32m+ libexpat        \u001b[0m      2.7.1  hecca717_0          conda-forge      75kB\r\n",
      "  \u001b[32m+ libffi          \u001b[0m      3.4.6  h2dba641_1          conda-forge      57kB\r\n",
      "  \u001b[32m+ libgcc          \u001b[0m     15.2.0  h767d61c_7          conda-forge     823kB\r\n",
      "  \u001b[32m+ libgomp         \u001b[0m     15.2.0  h767d61c_7          conda-forge     448kB\r\n",
      "  \u001b[32m+ liblzma         \u001b[0m      5.8.1  hb9d3cd8_2          conda-forge     113kB\r\n",
      "  \u001b[32m+ libmpdec        \u001b[0m      4.0.0  hb9d3cd8_0          conda-forge      91kB\r\n",
      "  \u001b[32m+ libsqlite       \u001b[0m     3.50.4  h0c1763c_0          conda-forge     933kB\r\n",
      "  \u001b[32m+ libuuid         \u001b[0m     2.41.2  he9a06e4_0          conda-forge      37kB\r\n",
      "  \u001b[32m+ libzlib         \u001b[0m      1.3.1  hb9d3cd8_2          conda-forge      61kB\r\n",
      "  \u001b[32m+ ncurses         \u001b[0m        6.5  h2d0b736_3          conda-forge     892kB\r\n",
      "  \u001b[32m+ openssl         \u001b[0m      3.5.4  h26f9b46_0          conda-forge       3MB\r\n",
      "  \u001b[32m+ pip             \u001b[0m       25.2  pyh145f28c_0        conda-forge       1MB\r\n",
      "  \u001b[32m+ python          \u001b[0m     3.13.7  h2b335a9_100_cp313  conda-forge      34MB\r\n",
      "  \u001b[32m+ python_abi      \u001b[0m       3.13  8_cp313             conda-forge       7kB\r\n",
      "  \u001b[32m+ readline        \u001b[0m        8.2  h8c095d6_2          conda-forge     282kB\r\n",
      "  \u001b[32m+ tk              \u001b[0m     8.6.13  noxft_hd72426e_102  conda-forge       3MB\r\n",
      "  \u001b[32m+ tzdata          \u001b[0m      2025b  h78e105d_0          conda-forge     123kB\r\n",
      "\r\n",
      "  Summary:\r\n",
      "\r\n",
      "  Install: 22 packages\r\n",
      "\r\n",
      "  Total download: 46MB\r\n",
      "\r\n",
      "────────────────────────────────────────────────────────────────────────────\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "Transaction starting\r\n",
      "\u001b[?25l\u001b[2K\u001b[0G[+] 0.0s\r\n",
      "Downloading      ╸\u001b[33m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m   0.0 B                            0.0s\r\n",
      "Extracting       \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m       0                            0.0s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 0.1s\r\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━   0.0 B                            0.0s\r\n",
      "Extracting       \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m       0                            0.0s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 0.2s\r\n",
      "Downloading  (5) \u001b[33m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m   0.0 B libsqlite                  0.0s\r\n",
      "Extracting       \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m       0                            0.0s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Gtk                                                   3.3MB @  12.1MB/s  0.1s\r\n",
      "openssl                                              3.1MB @   8.8MB/s  0.1s\r\n",
      "libsqlite                                          932.6kB @  ??.?MB/s  0.1s\r\n",
      "pip                                                  1.2MB @  ??.?MB/s  0.2s\r\n",
      "[+] 0.3s\r\n",
      "Downloading  (5) ━━━━━╸\u001b[33m━━━━━━━━━━━━━━━━━\u001b[0m  13.3MB ld_impl_linux-64           0.1s\r\n",
      "Extracting   (4) \u001b[90m━━━━━━━━━╸\u001b[0m\u001b[33m━━━━━━━━━━━━━\u001b[0m       0 libsqlite                  0.0s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Glibgcc                                             822.6kB @  ??.?MB/s  0.1s\r\n",
      "ncurses                                            891.6kB @   2.1MB/s  0.1s\r\n",
      "ld_impl_linux-64                                   747.2kB @  ??.?MB/s  0.1s\r\n",
      "libgomp                                            447.9kB @  ??.?MB/s  0.1s\r\n",
      "bzip2                                              260.3kB @   3.3MB/s  0.1s\r\n",
      "readline                                           282.5kB @  ??.?MB/s  0.1s\r\n",
      "[+] 0.4s\r\n",
      "Downloading  (4) ━━━━━━━━━━╸\u001b[33m━━━━━━━━━━━━\u001b[0m  22.9MB ca-certificates            0.2s\r\n",
      "Extracting   (8) ╸\u001b[33m━━━━━━━━╸\u001b[0m\u001b[90m━━━━━━━━━━━━━\u001b[0m       1 bzip2                      0.1s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Gtzdata                                             123.0kB @  ??.?MB/s  0.0s\r\n",
      "ca-certificates                                    155.9kB @  ??.?MB/s  0.1s\r\n",
      "liblzma                                            112.9kB @  ??.?MB/s  0.0s\r\n",
      "libexpat                                            74.8kB @  ??.?MB/s  0.1s\r\n",
      "libffi                                              57.4kB @  ??.?MB/s  0.1s\r\n",
      "[+] 0.5s\r\n",
      "Downloading  (5) ━━━━━━━━━━━━━━━━╸\u001b[33m━━━━━━\u001b[0m  35.9MB _openmp_mutex              0.3s\r\n",
      "Extracting   (9) ━━━━━╸\u001b[33m━━━━━━━━━╸\u001b[0m\u001b[90m━━━━━━━\u001b[0m       6 ca-certificates            0.2s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Glibmpdec                                            91.2kB @  ??.?MB/s  0.1s\r\n",
      "libzlib                                             61.0kB @  ??.?MB/s  0.1s\r\n",
      "libuuid                                             37.1kB @ 728.7kB/s  0.1s\r\n",
      "_libgcc_mutex                                        2.6kB @  ??.?MB/s  0.1s\r\n",
      "_openmp_mutex                                       23.6kB @  ??.?MB/s  0.1s\r\n",
      "python                                              33.6MB @  56.3MB/s  0.5s\r\n",
      "python_abi                                           7.0kB @  ??.?MB/s  0.1s\r\n",
      "[+] 0.6s\r\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━  46.3MB                            0.4s\r\n",
      "Extracting   (9) ━━━━━━━━━━━╸\u001b[33m━━━━━━━━━╸\u001b[0m\u001b[90m━\u001b[0m      12 _libgcc_mutex              0.3s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 0.7s\r\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━  46.3MB                            0.4s\r\n",
      "Extracting   (4) ━━━━━━━━━━━━━━━━╸\u001b[33m━━━━╸\u001b[0m\u001b[90m━\u001b[0m      17 _openmp_mutex              0.4s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 0.8s\r\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━  46.3MB                            0.4s\r\n",
      "Extracting   (1) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m      21 python                     0.5s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 0.9s\r\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━  46.3MB                            0.4s\r\n",
      "Extracting   (1) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m      21 python                     0.6s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 1.0s\r\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━  46.3MB                            0.4s\r\n",
      "Extracting   (1) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m      21 python                     0.7s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 1.1s\r\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━  46.3MB                            0.4s\r\n",
      "Extracting   (1) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m      21 python                     0.8s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 1.2s\r\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━  46.3MB                            0.4s\r\n",
      "Extracting   (1) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m      21 python                     0.9s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 1.3s\r\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━  46.3MB                            0.4s\r\n",
      "Extracting   (1) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m      21 python                     1.0s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G\u001b[?25hLinking ld_impl_linux-64-2.44-ha97dd6f_2\r\n",
      "Linking libgomp-15.2.0-h767d61c_7\r\n",
      "Linking _libgcc_mutex-0.1-conda_forge\r\n",
      "Linking _openmp_mutex-4.5-2_gnu\r\n",
      "Linking libgcc-15.2.0-h767d61c_7\r\n",
      "Linking libmpdec-4.0.0-hb9d3cd8_0\r\n",
      "Linking ncurses-6.5-h2d0b736_3\r\n",
      "Linking libzlib-1.3.1-hb9d3cd8_2\r\n",
      "Linking libuuid-2.41.2-he9a06e4_0\r\n",
      "Linking liblzma-5.8.1-hb9d3cd8_2\r\n",
      "Linking libffi-3.4.6-h2dba641_1\r\n",
      "Linking bzip2-1.0.8-hda65f42_8\r\n",
      "Linking libexpat-2.7.1-hecca717_0\r\n",
      "Linking readline-8.2-h8c095d6_2\r\n",
      "Linking libsqlite-3.50.4-h0c1763c_0\r\n",
      "Linking tk-8.6.13-noxft_hd72426e_102\r\n",
      "Linking python_abi-3.13-8_cp313\r\n",
      "Linking tzdata-2025b-h78e105d_0\r\n",
      "Linking ca-certificates-2025.10.5-hbd8a1cb_0\r\n",
      "Linking openssl-3.5.4-h26f9b46_0\r\n",
      "Linking python-3.13.7-h2b335a9_100_cp313\r\n",
      "Linking pip-25.2-pyh145f28c_0\r\n",
      "\r\n",
      "Transaction finished\r\n",
      "\r\n",
      "\r\n",
      "To activate this environment, use:\r\n",
      "\r\n",
      "    micromamba activate kernelltl\r\n",
      "\r\n",
      "Or to execute a single command in this environment, use:\r\n",
      "\r\n",
      "    micromamba run -n kernelltl mycommand\r\n",
      "\r\n",
      "Collecting accelerate==1.10.1 (from -r /kaggle/working/KernelLTL/requirements.txt (line 1))\r\n",
      "  Downloading accelerate-1.10.1-py3-none-any.whl.metadata (19 kB)\r\n",
      "Collecting certifi==2025.10.5 (from -r /kaggle/working/KernelLTL/requirements.txt (line 2))\r\n",
      "  Downloading certifi-2025.10.5-py3-none-any.whl.metadata (2.5 kB)\r\n",
      "Collecting charset-normalizer==3.4.3 (from -r /kaggle/working/KernelLTL/requirements.txt (line 3))\r\n",
      "  Downloading charset_normalizer-3.4.3-cp313-cp313-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (36 kB)\r\n",
      "Collecting filelock==3.20.0 (from -r /kaggle/working/KernelLTL/requirements.txt (line 4))\r\n",
      "  Downloading filelock-3.20.0-py3-none-any.whl.metadata (2.1 kB)\r\n",
      "Collecting fsspec==2025.9.0 (from -r /kaggle/working/KernelLTL/requirements.txt (line 5))\r\n",
      "  Downloading fsspec-2025.9.0-py3-none-any.whl.metadata (10 kB)\r\n",
      "Collecting hf-xet==1.1.10 (from -r /kaggle/working/KernelLTL/requirements.txt (line 6))\r\n",
      "  Downloading hf_xet-1.1.10-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.7 kB)\r\n",
      "Collecting huggingface-hub==0.35.3 (from -r /kaggle/working/KernelLTL/requirements.txt (line 7))\r\n",
      "  Downloading huggingface_hub-0.35.3-py3-none-any.whl.metadata (14 kB)\r\n",
      "Collecting idna==3.10 (from -r /kaggle/working/KernelLTL/requirements.txt (line 8))\r\n",
      "  Downloading idna-3.10-py3-none-any.whl.metadata (10 kB)\r\n",
      "Collecting Jinja2==3.1.6 (from -r /kaggle/working/KernelLTL/requirements.txt (line 9))\r\n",
      "  Downloading jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\r\n",
      "Collecting MarkupSafe==3.0.3 (from -r /kaggle/working/KernelLTL/requirements.txt (line 10))\r\n",
      "  Downloading markupsafe-3.0.3-cp313-cp313-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (2.7 kB)\r\n",
      "Collecting mpmath==1.3.0 (from -r /kaggle/working/KernelLTL/requirements.txt (line 11))\r\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\r\n",
      "Collecting networkx==3.5 (from -r /kaggle/working/KernelLTL/requirements.txt (line 12))\r\n",
      "  Downloading networkx-3.5-py3-none-any.whl.metadata (6.3 kB)\r\n",
      "Collecting numpy==2.3.3 (from -r /kaggle/working/KernelLTL/requirements.txt (line 13))\r\n",
      "  Downloading numpy-2.3.3-cp313-cp313-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (62 kB)\r\n",
      "Collecting nvidia-cublas-cu12==12.8.4.1 (from -r /kaggle/working/KernelLTL/requirements.txt (line 14))\r\n",
      "  Downloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\r\n",
      "Collecting nvidia-cuda-cupti-cu12==12.8.90 (from -r /kaggle/working/KernelLTL/requirements.txt (line 15))\r\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\r\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.8.93 (from -r /kaggle/working/KernelLTL/requirements.txt (line 16))\r\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\r\n",
      "Collecting nvidia-cuda-runtime-cu12==12.8.90 (from -r /kaggle/working/KernelLTL/requirements.txt (line 17))\r\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\r\n",
      "Collecting nvidia-cudnn-cu12==9.10.2.21 (from -r /kaggle/working/KernelLTL/requirements.txt (line 18))\r\n",
      "  Downloading nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\r\n",
      "Collecting nvidia-cufft-cu12==11.3.3.83 (from -r /kaggle/working/KernelLTL/requirements.txt (line 19))\r\n",
      "  Downloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\r\n",
      "Collecting nvidia-cufile-cu12==1.13.1.3 (from -r /kaggle/working/KernelLTL/requirements.txt (line 20))\r\n",
      "  Downloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\r\n",
      "Collecting nvidia-curand-cu12==10.3.9.90 (from -r /kaggle/working/KernelLTL/requirements.txt (line 21))\r\n",
      "  Downloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\r\n",
      "Collecting nvidia-cusolver-cu12==11.7.3.90 (from -r /kaggle/working/KernelLTL/requirements.txt (line 22))\r\n",
      "  Downloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\r\n",
      "Collecting nvidia-cusparse-cu12==12.5.8.93 (from -r /kaggle/working/KernelLTL/requirements.txt (line 23))\r\n",
      "  Downloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\r\n",
      "Collecting nvidia-cusparselt-cu12==0.7.1 (from -r /kaggle/working/KernelLTL/requirements.txt (line 24))\r\n",
      "  Downloading nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl.metadata (7.0 kB)\r\n",
      "Collecting nvidia-nccl-cu12==2.27.3 (from -r /kaggle/working/KernelLTL/requirements.txt (line 25))\r\n",
      "  Downloading nvidia_nccl_cu12-2.27.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\r\n",
      "Collecting nvidia-nvjitlink-cu12==12.8.93 (from -r /kaggle/working/KernelLTL/requirements.txt (line 26))\r\n",
      "  Downloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\r\n",
      "Collecting nvidia-nvtx-cu12==12.8.90 (from -r /kaggle/working/KernelLTL/requirements.txt (line 27))\r\n",
      "  Downloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\r\n",
      "Collecting packaging==25.0 (from -r /kaggle/working/KernelLTL/requirements.txt (line 28))\r\n",
      "  Downloading packaging-25.0-py3-none-any.whl.metadata (3.3 kB)\r\n",
      "Collecting psutil==7.1.0 (from -r /kaggle/working/KernelLTL/requirements.txt (line 29))\r\n",
      "  Downloading psutil-7.1.0-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (23 kB)\r\n",
      "Collecting PyYAML==6.0.3 (from -r /kaggle/working/KernelLTL/requirements.txt (line 30))\r\n",
      "  Downloading pyyaml-6.0.3-cp313-cp313-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (2.4 kB)\r\n",
      "Collecting regex==2025.9.18 (from -r /kaggle/working/KernelLTL/requirements.txt (line 31))\r\n",
      "  Downloading regex-2025.9.18-cp313-cp313-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (40 kB)\r\n",
      "Collecting requests==2.32.5 (from -r /kaggle/working/KernelLTL/requirements.txt (line 32))\r\n",
      "  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\r\n",
      "Collecting safetensors==0.6.2 (from -r /kaggle/working/KernelLTL/requirements.txt (line 33))\r\n",
      "  Downloading safetensors-0.6.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\r\n",
      "Collecting setuptools==80.9.0 (from -r /kaggle/working/KernelLTL/requirements.txt (line 34))\r\n",
      "  Downloading setuptools-80.9.0-py3-none-any.whl.metadata (6.6 kB)\r\n",
      "Collecting sympy==1.14.0 (from -r /kaggle/working/KernelLTL/requirements.txt (line 35))\r\n",
      "  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\r\n",
      "Collecting tokenizers==0.22.1 (from -r /kaggle/working/KernelLTL/requirements.txt (line 36))\r\n",
      "  Downloading tokenizers-0.22.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\r\n",
      "Collecting torch==2.8.0 (from -r /kaggle/working/KernelLTL/requirements.txt (line 37))\r\n",
      "  Downloading torch-2.8.0-cp313-cp313-manylinux_2_28_x86_64.whl.metadata (30 kB)\r\n",
      "Collecting tqdm==4.67.1 (from -r /kaggle/working/KernelLTL/requirements.txt (line 38))\r\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\r\n",
      "Collecting transformers==4.57.0 (from -r /kaggle/working/KernelLTL/requirements.txt (line 39))\r\n",
      "  Downloading transformers-4.57.0-py3-none-any.whl.metadata (41 kB)\r\n",
      "Collecting triton==3.4.0 (from -r /kaggle/working/KernelLTL/requirements.txt (line 40))\r\n",
      "  Downloading triton-3.4.0-cp313-cp313-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.7 kB)\r\n",
      "Collecting typing_extensions==4.15.0 (from -r /kaggle/working/KernelLTL/requirements.txt (line 41))\r\n",
      "  Downloading typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\r\n",
      "Collecting urllib3==2.5.0 (from -r /kaggle/working/KernelLTL/requirements.txt (line 42))\r\n",
      "  Downloading urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)\r\n",
      "Downloading accelerate-1.10.1-py3-none-any.whl (374 kB)\r\n",
      "Downloading numpy-2.3.3-cp313-cp313-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.6 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.6/16.6 MB\u001b[0m \u001b[31m101.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading certifi-2025.10.5-py3-none-any.whl (163 kB)\r\n",
      "Downloading charset_normalizer-3.4.3-cp313-cp313-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (151 kB)\r\n",
      "Downloading filelock-3.20.0-py3-none-any.whl (16 kB)\r\n",
      "Downloading fsspec-2025.9.0-py3-none-any.whl (199 kB)\r\n",
      "Downloading hf_xet-1.1.10-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m90.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading huggingface_hub-0.35.3-py3-none-any.whl (564 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m564.3/564.3 kB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading idna-3.10-py3-none-any.whl (70 kB)\r\n",
      "Downloading jinja2-3.1.6-py3-none-any.whl (134 kB)\r\n",
      "Downloading markupsafe-3.0.3-cp313-cp313-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (22 kB)\r\n",
      "Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading networkx-3.5-py3-none-any.whl (2.0 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m75.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl (594.3 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m594.3/594.3 MB\u001b[0m \u001b[31m55.7 MB/s\u001b[0m  \u001b[33m0:00:06\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (10.2 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m112.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (88.0 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.0/88.0 MB\u001b[0m \u001b[31m103.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (954 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m954.8/954.8 kB\u001b[0m \u001b[31m36.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl (706.8 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m706.8/706.8 MB\u001b[0m \u001b[31m35.3 MB/s\u001b[0m  \u001b[33m0:00:09\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (193.1 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.1/193.1 MB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m  \u001b[33m0:00:08\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.2 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m43.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl (63.6 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.6/63.6 MB\u001b[0m \u001b[31m108.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl (267.5 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m267.5/267.5 MB\u001b[0m \u001b[31m96.9 MB/s\u001b[0m  \u001b[33m0:00:02\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (288.2 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m288.2/288.2 MB\u001b[0m \u001b[31m93.7 MB/s\u001b[0m  \u001b[33m0:00:02\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl (287.2 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m287.2/287.2 MB\u001b[0m \u001b[31m93.6 MB/s\u001b[0m  \u001b[33m0:00:02\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_nccl_cu12-2.27.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (322.4 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.4/322.4 MB\u001b[0m \u001b[31m75.8 MB/s\u001b[0m  \u001b[33m0:00:03\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (39.3 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.3/39.3 MB\u001b[0m \u001b[31m115.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\r\n",
      "Downloading packaging-25.0-py3-none-any.whl (66 kB)\r\n",
      "Downloading psutil-7.1.0-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (291 kB)\r\n",
      "Downloading pyyaml-6.0.3-cp313-cp313-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (801 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m801.6/801.6 kB\u001b[0m \u001b[31m35.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading regex-2025.9.18-cp313-cp313-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (802 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m802.1/802.1 kB\u001b[0m \u001b[31m32.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading requests-2.32.5-py3-none-any.whl (64 kB)\r\n",
      "Downloading urllib3-2.5.0-py3-none-any.whl (129 kB)\r\n",
      "Downloading safetensors-0.6.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (485 kB)\r\n",
      "Downloading setuptools-80.9.0-py3-none-any.whl (1.2 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m50.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m113.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading tokenizers-0.22.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m99.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading torch-2.8.0-cp313-cp313-manylinux_2_28_x86_64.whl (887.9 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m887.9/887.9 MB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m  \u001b[33m0:00:16\u001b[0m\r\n",
      "\u001b[?25hDownloading tqdm-4.67.1-py3-none-any.whl (78 kB)\r\n",
      "Downloading transformers-4.57.0-py3-none-any.whl (12.0 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading triton-3.4.0-cp313-cp313-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (155.6 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.6/155.6 MB\u001b[0m \u001b[31m71.3 MB/s\u001b[0m  \u001b[33m0:00:02\u001b[0m\r\n",
      "\u001b[?25hDownloading typing_extensions-4.15.0-py3-none-any.whl (44 kB)\r\n",
      "Installing collected packages: nvidia-cusparselt-cu12, mpmath, urllib3, typing_extensions, tqdm, sympy, setuptools, safetensors, regex, PyYAML, psutil, packaging, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, networkx, MarkupSafe, idna, hf-xet, fsspec, filelock, charset-normalizer, certifi, triton, requests, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, Jinja2, nvidia-cusolver-cu12, huggingface-hub, torch, tokenizers, transformers, accelerate\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42/42\u001b[0m [accelerate]\r\n",
      "\u001b[1A\u001b[2KSuccessfully installed Jinja2-3.1.6 MarkupSafe-3.0.3 PyYAML-6.0.3 accelerate-1.10.1 certifi-2025.10.5 charset-normalizer-3.4.3 filelock-3.20.0 fsspec-2025.9.0 hf-xet-1.1.10 huggingface-hub-0.35.3 idna-3.10 mpmath-1.3.0 networkx-3.5 numpy-2.3.3 nvidia-cublas-cu12-12.8.4.1 nvidia-cuda-cupti-cu12-12.8.90 nvidia-cuda-nvrtc-cu12-12.8.93 nvidia-cuda-runtime-cu12-12.8.90 nvidia-cudnn-cu12-9.10.2.21 nvidia-cufft-cu12-11.3.3.83 nvidia-cufile-cu12-1.13.1.3 nvidia-curand-cu12-10.3.9.90 nvidia-cusolver-cu12-11.7.3.90 nvidia-cusparse-cu12-12.5.8.93 nvidia-cusparselt-cu12-0.7.1 nvidia-nccl-cu12-2.27.3 nvidia-nvjitlink-cu12-12.8.93 nvidia-nvtx-cu12-12.8.90 packaging-25.0 psutil-7.1.0 regex-2025.9.18 requests-2.32.5 safetensors-0.6.2 setuptools-80.9.0 sympy-1.14.0 tokenizers-0.22.1 torch-2.8.0 tqdm-4.67.1 transformers-4.57.0 triton-3.4.0 typing_extensions-4.15.0 urllib3-2.5.0\r\n"
     ]
    }
   ],
   "source": [
    "!wget -qO- https://micro.mamba.pm/api/micromamba/linux-64/latest | tar -xvj bin/micromamba\n",
    "!./bin/micromamba create -y -n kernelltl -c conda-forge python=3.13.7 pip\n",
    "!./bin/micromamba run -n kernelltl pip install -r /kaggle/working/KernelLTL/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86458009",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-13T14:30:35.750531Z",
     "iopub.status.busy": "2025-10-13T14:30:35.749748Z",
     "iopub.status.idle": "2025-10-13T14:30:42.932387Z",
     "shell.execute_reply": "2025-10-13T14:30:42.931570Z"
    },
    "papermill": {
     "duration": 7.279453,
     "end_time": "2025-10-13T14:30:42.933883",
     "exception": false,
     "start_time": "2025-10-13T14:30:35.654430",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/.local/share/mamba/envs/kernelltl/lib/python3.13/site-packages/torch/cuda/__init__.py:283: UserWarning: \r\n",
      "    Found GPU0 Tesla P100-PCIE-16GB which is of cuda capability 6.0.\r\n",
      "    Minimum and Maximum cuda capability supported by this version of PyTorch is\r\n",
      "    (7.0) - (12.0)\r\n",
      "    \r\n",
      "  warnings.warn(\r\n",
      "/root/.local/share/mamba/envs/kernelltl/lib/python3.13/site-packages/torch/cuda/__init__.py:304: UserWarning: \r\n",
      "    Please install PyTorch with a following CUDA\r\n",
      "    configurations:  12.6 following instructions at\r\n",
      "    https://pytorch.org/get-started/locally/\r\n",
      "    \r\n",
      "  warnings.warn(matched_cuda_warn.format(matched_arches))\r\n",
      "/root/.local/share/mamba/envs/kernelltl/lib/python3.13/site-packages/torch/cuda/__init__.py:326: UserWarning: \r\n",
      "Tesla P100-PCIE-16GB with CUDA capability sm_60 is not compatible with the current PyTorch installation.\r\n",
      "The current PyTorch install supports CUDA capabilities sm_70 sm_75 sm_80 sm_86 sm_90 sm_100 sm_120.\r\n",
      "If you want to use the Tesla P100-PCIE-16GB GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/\r\n",
      "\r\n",
      "  warnings.warn(\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \u001b[35m\"<frozen runpy>\"\u001b[0m, line \u001b[35m198\u001b[0m, in \u001b[35m_run_module_as_main\u001b[0m\r\n",
      "  File \u001b[35m\"<frozen runpy>\"\u001b[0m, line \u001b[35m88\u001b[0m, in \u001b[35m_run_code\u001b[0m\r\n",
      "  File \u001b[35m\"/kaggle/working/KernelLTL/train.py\"\u001b[0m, line \u001b[35m132\u001b[0m, in \u001b[35m<module>\u001b[0m\r\n",
      "    \u001b[31mmain\u001b[0m\u001b[1;31m()\u001b[0m\r\n",
      "    \u001b[31m~~~~\u001b[0m\u001b[1;31m^^\u001b[0m\r\n",
      "  File \u001b[35m\"/kaggle/working/KernelLTL/train.py\"\u001b[0m, line \u001b[35m42\u001b[0m, in \u001b[35mmain\u001b[0m\r\n",
      "    \u001b[31mkernel.sample_traces_kernel\u001b[0m\u001b[1;31m(N)\u001b[0m  # adjust N based on your needs\r\n",
      "    \u001b[31m~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^^\u001b[0m\r\n",
      "  File \u001b[35m\"/kaggle/working/KernelLTL/kernel_class.py\"\u001b[0m, line \u001b[35m46\u001b[0m, in \u001b[35msample_traces_kernel\u001b[0m\r\n",
      "    self.traces = \u001b[31msample_traces\u001b[0m\u001b[1;31m(N,\u001b[0m\r\n",
      "                  \u001b[31m~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^^\u001b[0m\r\n",
      "                                \u001b[1;31mn_ap=self.AP,\u001b[0m\r\n",
      "                                \u001b[1;31m^^^^^^^^^^^^^\u001b[0m\r\n",
      "                                \u001b[1;31mtrace_length=self.T,\u001b[0m\r\n",
      "                                \u001b[1;31m^^^^^^^^^^^^^^^^^^^^\u001b[0m\r\n",
      "                                \u001b[1;31mrng=self.rng,\u001b[0m\r\n",
      "                                \u001b[1;31m^^^^^^^^^^^^^\u001b[0m\r\n",
      "                                \u001b[1;31mdevice=self.device)\u001b[0m\r\n",
      "                                \u001b[1;31m^^^^^^^^^^^^^^^^^^^\u001b[0m\r\n",
      "  File \u001b[35m\"/kaggle/working/KernelLTL/formula_utils.py\"\u001b[0m, line \u001b[35m101\u001b[0m, in \u001b[35msample_traces\u001b[0m\r\n",
      "    traces = torch.randint(0,2, size=(n_traces, n_ap, trace_length), generator=rng, dtype=torch.bool, device = device)\r\n",
      "\u001b[1;35mtorch.AcceleratorError\u001b[0m: \u001b[35mCUDA error: no kernel image is available for execution on the device\r\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\r\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\r\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\r\n",
      "\u001b[0m\r\n",
      "E1013 14:30:42.461000 198 site-packages/torch/distributed/elastic/multiprocessing/api.py:874] failed (exitcode: 1) local_rank: 0 (pid: 210) of binary: /root/.local/share/mamba/envs/kernelltl/bin/python3.13\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \u001b[35m\"/root/.local/share/mamba/envs/kernelltl/bin/torchrun\"\u001b[0m, line \u001b[35m7\u001b[0m, in \u001b[35m<module>\u001b[0m\r\n",
      "    sys.exit(\u001b[31mmain\u001b[0m\u001b[1;31m()\u001b[0m)\r\n",
      "             \u001b[31m~~~~\u001b[0m\u001b[1;31m^^\u001b[0m\r\n",
      "  File \u001b[35m\"/root/.local/share/mamba/envs/kernelltl/lib/python3.13/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py\"\u001b[0m, line \u001b[35m357\u001b[0m, in \u001b[35mwrapper\u001b[0m\r\n",
      "    return f(*args, **kwargs)\r\n",
      "  File \u001b[35m\"/root/.local/share/mamba/envs/kernelltl/lib/python3.13/site-packages/torch/distributed/run.py\"\u001b[0m, line \u001b[35m901\u001b[0m, in \u001b[35mmain\u001b[0m\r\n",
      "    \u001b[31mrun\u001b[0m\u001b[1;31m(args)\u001b[0m\r\n",
      "    \u001b[31m~~~\u001b[0m\u001b[1;31m^^^^^^\u001b[0m\r\n",
      "  File \u001b[35m\"/root/.local/share/mamba/envs/kernelltl/lib/python3.13/site-packages/torch/distributed/run.py\"\u001b[0m, line \u001b[35m892\u001b[0m, in \u001b[35mrun\u001b[0m\r\n",
      "    \u001b[31melastic_launch(\u001b[0m\r\n",
      "    \u001b[31m~~~~~~~~~~~~~~~\u001b[0m\r\n",
      "        \u001b[31mconfig=config,\u001b[0m\r\n",
      "        \u001b[31m~~~~~~~~~~~~~~\u001b[0m\r\n",
      "        \u001b[31mentrypoint=cmd,\u001b[0m\r\n",
      "        \u001b[31m~~~~~~~~~~~~~~~\u001b[0m\r\n",
      "    \u001b[31m)\u001b[0m\u001b[1;31m(*cmd_args)\u001b[0m\r\n",
      "    \u001b[31m~\u001b[0m\u001b[1;31m^^^^^^^^^^^\u001b[0m\r\n",
      "  File \u001b[35m\"/root/.local/share/mamba/envs/kernelltl/lib/python3.13/site-packages/torch/distributed/launcher/api.py\"\u001b[0m, line \u001b[35m143\u001b[0m, in \u001b[35m__call__\u001b[0m\r\n",
      "    return launch_agent(self._config, self._entrypoint, list(args))\r\n",
      "  File \u001b[35m\"/root/.local/share/mamba/envs/kernelltl/lib/python3.13/site-packages/torch/distributed/launcher/api.py\"\u001b[0m, line \u001b[35m277\u001b[0m, in \u001b[35mlaunch_agent\u001b[0m\r\n",
      "    raise ChildFailedError(\r\n",
      "    ...<2 lines>...\r\n",
      "    )\r\n",
      "\u001b[1;35mtorch.distributed.elastic.multiprocessing.errors.ChildFailedError\u001b[0m: \u001b[35m\r\n",
      "============================================================\r\n",
      "train FAILED\r\n",
      "------------------------------------------------------------\r\n",
      "Failures:\r\n",
      "  <NO_OTHER_FAILURES>\r\n",
      "------------------------------------------------------------\r\n",
      "Root Cause (first observed failure):\r\n",
      "[0]:\r\n",
      "  time      : 2025-10-13_14:30:42\r\n",
      "  host      : 85b817eebb59\r\n",
      "  rank      : 0 (local_rank: 0)\r\n",
      "  exitcode  : 1 (pid: 210)\r\n",
      "  error_file: <N/A>\r\n",
      "  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html\r\n",
      "============================================================\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!cd /kaggle/working/KernelLTL && \\\n",
    " PYTHONPATH=$PWD /kaggle/working/bin/micromamba run -n kernelltl \\\n",
    " torchrun --nproc_per_node=1 -m train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ce7ce0c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-13T14:30:43.012297Z",
     "iopub.status.busy": "2025-10-13T14:30:43.012008Z",
     "iopub.status.idle": "2025-10-13T14:30:43.838206Z",
     "shell.execute_reply": "2025-10-13T14:30:43.837458Z"
    },
    "papermill": {
     "duration": 0.866703,
     "end_time": "2025-10-13T14:30:43.839470",
     "exception": false,
     "start_time": "2025-10-13T14:30:42.972767",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\"ref\": \"\", \"url\": \"https://www.kaggle.com/\", \"status\": \"Error\", \"error\": \"Please upload at least one file\", \"invalidTags\": []}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, json, shutil\n",
    "\n",
    "import os, shutil\n",
    "os.makedirs(\"/root/.kaggle\", exist_ok=True)\n",
    "shutil.copy(\"/kaggle/input/kaggle-api-token/kaggle.json\", \"/root/.kaggle/kaggle.json\")\n",
    "os.chmod(\"/root/.kaggle/kaggle.json\", 0o600)\n",
    "\n",
    "from kaggle import api\n",
    "ds_dir = \"/kaggle/working/KernelLTL/ltl_model_outputs\"\n",
    "os.makedirs(ds_dir, exist_ok=True)\n",
    "\n",
    "metadata = {\n",
    "    \"title\": \"LTL model outputs\",\n",
    "    \"id\": \"tayhnd5sgdtjevyreuw/kernel-ltl-model-outputs\",\n",
    "    \"licenses\": [{\"name\": \"CC0-1.0\"}]\n",
    "}\n",
    "with open(os.path.join(ds_dir, \"dataset-metadata.json\"), \"w\") as f:\n",
    "    json.dump(metadata, f, indent=2)\n",
    "\n",
    "api.dataset_create_new(ds_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c757bf",
   "metadata": {
    "papermill": {
     "duration": 0.038317,
     "end_time": "2025-10-13T14:30:43.917248",
     "exception": false,
     "start_time": "2025-10-13T14:30:43.878931",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "'''\n",
    "import shutil, os\n",
    "\n",
    "def kaggle_export(output_dir, zip_name):\n",
    "    \"\"\"Create a zip file and export your work in the kaggle working directory.\n",
    "    Args:\n",
    "        output_dir (str): The path to the directory to be zipped.\n",
    "        zip_name (str): The name of the zip file to be created.\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    if not os.path.exists(output_dir):\n",
    "        print(f\"[Error]: output directory '{output_dir}' does not exist\")\n",
    "    \n",
    "    else:\n",
    "        try:\n",
    "            shutil.make_archive(zip_name, 'zip', output_dir)\n",
    "            print(f\"[Success]: Your zip file is successfully created!\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"[Error]: An error occurred while creating zip: {e}\")\n",
    "\n",
    "kaggle_export(\"/kaggle/working/KernelLTL/ltl_model_outputs\", \"model_outputs\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9abe6c1",
   "metadata": {
    "papermill": {
     "duration": 0.03818,
     "end_time": "2025-10-13T14:30:43.993330",
     "exception": false,
     "start_time": "2025-10-13T14:30:43.955150",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "'''\n",
    "import math\n",
    "import os\n",
    "import torch\n",
    "\n",
    "# Hyperparameters\n",
    "num_epochs = 10\n",
    "\n",
    "learning_rate = 5e-5\n",
    "\n",
    "T       = 20\n",
    "AP      = 5\n",
    "seed    = 1\n",
    "\n",
    "eps     = 0.01\n",
    "delta   = 1 - 0.99\n",
    "N       = math.ceil((2 / eps**2) * math.log(2 / delta))\n",
    "\n",
    "m       = 1024\n",
    "    \n",
    "# Create output directory\n",
    "output_dir = \"ltl_model_outputs\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "local_rank = int(os.environ.get(\"LOCAL_RANK\", -1))\n",
    "if local_rank != -1 and torch.cuda.is_available():\n",
    "    torch.cuda.set_device(local_rank)\n",
    "# os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\"\n",
    "# torch.use_deterministic_algorithms(True)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d90867d7",
   "metadata": {
    "papermill": {
     "duration": 0.038515,
     "end_time": "2025-10-13T14:30:44.069945",
     "exception": false,
     "start_time": "2025-10-13T14:30:44.031430",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "'''\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from tokenizer_class import LTLTokenizer\n",
    "from kernel_class import LTLKernel\n",
    "from dataset_class import LTLDataset\n",
    "\n",
    "# Initialize tokenizer (adjust n_ap based on your needs)\n",
    "tokenizer = LTLTokenizer(n_ap=AP)\n",
    "\n",
    "# Initialize kernel for semantic embeddings\n",
    "kernel = LTLKernel(T, AP, seed)  # adjust T and AP as needed\n",
    "kernel.sample_traces_kernel(N)  # adjust N based on your needs\n",
    "kernel.sample_anchor_formulas_kernel(m)  # m should match model's n_embd\n",
    "kernel.build_F()\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = LTLDataset()\n",
    "train_dataset.construct_dataset_from_kernel(\n",
    "    kernel=kernel,\n",
    "    k=78000,  # adjust dataset size as needed\n",
    "    p_leaf=0.45,\n",
    "    max_depth=1000,\n",
    "    batch_size=10240\n",
    ")\n",
    "\n",
    "eval_dataset = LTLDataset()\n",
    "eval_dataset.construct_dataset_from_kernel(\n",
    "    kernel=kernel,\n",
    "    k=1000,  # smaller validation set\n",
    "    p_leaf=0.45,\n",
    "    max_depth=1000,\n",
    "    batch_size=10240\n",
    ")\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a9b656",
   "metadata": {
    "papermill": {
     "duration": 0.038447,
     "end_time": "2025-10-13T14:30:44.146726",
     "exception": false,
     "start_time": "2025-10-13T14:30:44.108279",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "'''\n",
    "from model_class import LTLModel\n",
    "from config_class import LTLConfig\n",
    "from training_utils import SemanticEvaluationCallback\n",
    "\n",
    "# Create model configuration and model\n",
    "config = LTLConfig(\n",
    "    n_embd=m  # must match kernel's anchor set size (m)\n",
    ")\n",
    "\n",
    "model = LTLModel(config, semantic_emb_dim=m)  # semantic_emb_dim must match kernel's anchor set size\n",
    "\n",
    "# Training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    num_train_epochs=num_epochs,\n",
    "    learning_rate=learning_rate,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=f\"{output_dir}/logs\",\n",
    "    logging_steps=100,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    greater_is_better=False,\n",
    "    dataloader_num_workers=4,\n",
    "    dataloader_pin_memory=True,\n",
    "    ddp_find_unused_parameters=False\n",
    ")\n",
    "\n",
    "# Initialize callback\n",
    "semantic_callback = SemanticEvaluationCallback(\n",
    "    kernel=kernel,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "# Create trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=lambda batch : tokenizer.collate_batch(batch, model.config.n_positions),\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    processing_class=tokenizer,\n",
    "    callbacks=[semantic_callback]\n",
    ")\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88bd3bbd",
   "metadata": {
    "papermill": {
     "duration": 0.038411,
     "end_time": "2025-10-13T14:30:44.223085",
     "exception": false,
     "start_time": "2025-10-13T14:30:44.184674",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "'''\n",
    "# Train\n",
    "trainer.train()\n",
    "\n",
    "# Save final model\n",
    "trainer.save_model(os.path.join(output_dir, \"final_model\"))\n",
    "tokenizer.save_vocab(os.path.join(output_dir, \"vocab.json\"))\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 8481667,
     "sourceId": 13369742,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 207.721346,
   "end_time": "2025-10-13T14:30:44.579131",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-10-13T14:27:16.857785",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
